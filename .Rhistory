echo = FALSE # FALSE to avoid printing intermediate results
# parameters for consensus community detection
n_trials = 10
alphas = c(0.0, 0.05, 0.1)
res = c(0.9, 1.0, 1.1)
epsilon = 1/100
# pruning
min_p <- 0.50
min_vds <- 5
min_w <- 0.01
# consensus
reps = 10
load_network <- function(path, filename) {
fn <- paste0(path,filename, ".graphml")
print(paste("Loading", fn, "..."))
g <- read_graph(fn, format = "graphml")
E(g)$ww <- E(g)$weight
V(g)$str <- strength(g)
V(g)$name <- paste0("V" , V(g)$name)
degrees <- degree(g)
kcore <- coreness(g)
print(paste("Number of nodes:", length(V(g)$name)))
print(paste("Number of edges:", length(E(g)$weight)))
print(paste("Mean degree:", mean(degrees)))
print(paste("Max k-coreness: ", max(kcore)))
return(g)
}
g <- load_network(path, filename)
dfresults <- consensus_community_detection(g,
alphas, reps, n_trials,
epsilon, res, min_p, min_vds, min_w,
echo = FALSE)
json_data <- toJSON(dfresults)
write(json_data, file=paste0(filename,"_results.json"))
print("Completed.")
dfresults  %>% filter(method == "LV") %>%
ggplot( aes(x = modularit, y =  nc , group = a)) +
facet_grid(cols = vars(a)) +
geom_line() +
geom_point() +
labs(title = "numbero of communities for alpha = (0.0 ,  0.1 , 0.2)",
x = "modularity",
y = "number of communities")
json_data <- fromJSON(paste0(filename,"_results.json"))
cols_to_extract <- c('method', "a",'rep', 'trial')
tmp_list <- list()
nn <- length(cols_to_extract)
for (i in 1:nn){
tmp_list[[i]] <- pluck(json_data, cols_to_extract[i])
}
df <- data.frame(tmp_list)
names(df) <- cols_to_extract
robs <-   pluck(json_data, "rob_mem")
n_trials = length(robs)
n_nodes <- 1000
# extract robustness, which is a list of 1000 where method == CONS
# and an empty list otherwise
for (i in 1:n_trials){
if (df$method[i] == "CONS"){
df$rob[i] <- list(robs[[i]])
} else {
df$rob[i] <- list(rep(-1, n_nodes))
}
}
# identify the node
df$id <- seq.int(nrow(df))
df <- df  %>% filter( method == "CONS")
# tidy dataset ready for plotting
df2 <- df %>%
unnest(rob) %>%
pivot_longer(cols = c(rob), names_to = 'tmp', values_to = 'rob')  %>%
select(-tmp) %>%
arrange(rep, trial, a, method, id,   rob)
df2  %>% ggplot( aes(x = rob)) +
facet_grid(cols = vars(a)) +
geom_density( adjust = 3,  color = "red") +
geom_histogram(aes(y = ..density..),
position = "identity",
alpha = 0.5) +
labs(title = "proportion of membership for alpha = (0.0 ,  0.1 , 0.2)",
x = "proportion of membership",
y = "Percentage")
filename <- "management_1115"
library(igraph)
source('source_functions_cons_com_det.r')
path <- "./networks/"
echo = FALSE # FALSE to avoid printing intermediate results
# parameters for consensus community detection
n_trials = 10
alphas = c(0.0, 0.05, 0.1)
res = c(0.9, 1.0, 1.1)
epsilon = 1/100
# pruning
min_p <- 0.50
min_vds <- 5
min_w <- 0.01
# consensus
reps = 10
load_network <- function(path, filename) {
fn <- paste0(path,filename, ".graphml")
print(paste("Loading", fn, "..."))
g <- read_graph(fn, format = "graphml")
E(g)$ww <- E(g)$weight
V(g)$str <- strength(g)
V(g)$name <- paste0("V" , V(g)$name)
degrees <- degree(g)
kcore <- coreness(g)
print(paste("Number of nodes:", length(V(g)$name)))
print(paste("Number of edges:", length(E(g)$weight)))
print(paste("Mean degree:", mean(degrees)))
print(paste("Max k-coreness: ", max(kcore)))
return(g)
}
g <- load_network(path, filename)
dfresults <- consensus_community_detection(g,
alphas, reps, n_trials,
epsilon, res, min_p, min_vds, min_w,
echo = FALSE)
json_data <- toJSON(dfresults)
write(json_data, file=paste0(filename,"_results.json"))
print("Completed.")
dfresults  %>% filter(method == "LV") %>%
ggplot( aes(x = modularit, y =  nc , group = a)) +
facet_grid(cols = vars(a)) +
geom_line() +
geom_point() +
labs(title = "numbero of communities for alpha = (0.0 ,  0.1 , 0.2)",
x = "modularity",
y = "number of communities")
json_data <- fromJSON(paste0(filename,"_results.json"))
cols_to_extract <- c('method', "a",'rep', 'trial')
tmp_list <- list()
nn <- length(cols_to_extract)
for (i in 1:nn){
tmp_list[[i]] <- pluck(json_data, cols_to_extract[i])
}
df <- data.frame(tmp_list)
names(df) <- cols_to_extract
robs <-   pluck(json_data, "rob_mem")
n_trials = length(robs)
n_nodes <- 1000
# extract robustness, which is a list of 1000 where method == CONS
# and an empty list otherwise
for (i in 1:n_trials){
if (df$method[i] == "CONS"){
df$rob[i] <- list(robs[[i]])
} else {
df$rob[i] <- list(rep(-1, n_nodes))
}
}
# identify the node
df$id <- seq.int(nrow(df))
df <- df  %>% filter( method == "CONS")
# tidy dataset ready for plotting
df2 <- df %>%
unnest(rob) %>%
pivot_longer(cols = c(rob), names_to = 'tmp', values_to = 'rob')  %>%
select(-tmp) %>%
arrange(rep, trial, a, method, id,   rob)
df2  %>% ggplot( aes(x = rob)) +
facet_grid(cols = vars(a)) +
geom_density( adjust = 3,  color = "red") +
geom_histogram(aes(y = ..density..),
position = "identity",
alpha = 0.5) +
labs(title = "proportion of membership for alpha = (0.0 ,  0.1 , 0.2)",
x = "proportion of membership",
y = "Percentage")
filename <- "management_1115"
library(igraph)
source('source_functions_cons_com_det.r')
path <- "./networks/"
echo = FALSE # FALSE to avoid printing intermediate results
# parameters for consensus community detection
n_trials = 10
alphas = c(0.0, 0.05, 0.1)
res = c(0.9, 1.0, 1.1)
epsilon = 1/100
# pruning
min_p <- 0.50
min_vds <- 5
min_w <- 0.01
# consensus
reps = 10
load_network <- function(path, filename) {
fn <- paste0(path,filename, ".graphml")
print(paste("Loading", fn, "..."))
g <- read_graph(fn, format = "graphml")
E(g)$ww <- E(g)$weight
V(g)$str <- strength(g)
V(g)$name <- paste0("V" , V(g)$name)
degrees <- degree(g)
kcore <- coreness(g)
print(paste("Number of nodes:", length(V(g)$name)))
print(paste("Number of edges:", length(E(g)$weight)))
print(paste("Mean degree:", mean(degrees)))
print(paste("Max k-coreness: ", max(kcore)))
return(g)
}
g <- load_network(path, filename)
dfresults <- consensus_community_detection(g,
alphas, reps, n_trials,
epsilon, res, min_p, min_vds, min_w,
echo = FALSE)
json_data <- toJSON(dfresults)
write(json_data, file=paste0(filename,"_results.json"))
print("Completed.")
dfresults  %>% filter(method == "LV") %>%
ggplot( aes(x = modularit, y =  nc , group = a)) +
facet_grid(cols = vars(a)) +
geom_line() +
geom_point() +
labs(title = "numbero of communities for alpha = (0.0 ,  0.1 , 0.2)",
x = "modularity",
y = "number of communities")
json_data <- fromJSON(paste0(filename,"_results.json"))
cols_to_extract <- c('method', "a",'rep', 'trial')
tmp_list <- list()
nn <- length(cols_to_extract)
for (i in 1:nn){
tmp_list[[i]] <- pluck(json_data, cols_to_extract[i])
}
df <- data.frame(tmp_list)
names(df) <- cols_to_extract
robs <-   pluck(json_data, "rob_mem")
n_trials = length(robs)
n_nodes <- 1000
# extract robustness, which is a list of 1000 where method == CONS
# and an empty list otherwise
for (i in 1:n_trials){
if (df$method[i] == "CONS"){
df$rob[i] <- list(robs[[i]])
} else {
df$rob[i] <- list(rep(-1, n_nodes))
}
}
# identify the node
df$id <- seq.int(nrow(df))
df <- df  %>% filter( method == "CONS")
# tidy dataset ready for plotting
df2 <- df %>%
unnest(rob) %>%
pivot_longer(cols = c(rob), names_to = 'tmp', values_to = 'rob')  %>%
select(-tmp) %>%
arrange(rep, trial, a, method, id,   rob)
df2  %>% ggplot( aes(x = rob)) +
facet_grid(cols = vars(a)) +
geom_density( adjust = 3,  color = "red") +
geom_histogram(aes(y = ..density..),
position = "identity",
alpha = 0.5) +
labs(title = "proportion of membership for alpha = (0.0 ,  0.1 , 0.2)",
x = "proportion of membership",
y = "Percentage")
filename <- "management_1619"
library(igraph)
source('source_functions_cons_com_det.r')
path <- "./networks/"
echo = FALSE # FALSE to avoid printing intermediate results
# parameters for consensus community detection
n_trials = 10
alphas = c(0.0, 0.05, 0.1)
res = c(0.9, 1.0, 1.1)
epsilon = 1/100
# pruning
min_p <- 0.50
min_vds <- 5
min_w <- 0.01
# consensus
reps = 10
load_network <- function(path, filename) {
fn <- paste0(path,filename, ".graphml")
print(paste("Loading", fn, "..."))
g <- read_graph(fn, format = "graphml")
E(g)$ww <- E(g)$weight
V(g)$str <- strength(g)
V(g)$name <- paste0("V" , V(g)$name)
degrees <- degree(g)
kcore <- coreness(g)
print(paste("Number of nodes:", length(V(g)$name)))
print(paste("Number of edges:", length(E(g)$weight)))
print(paste("Mean degree:", mean(degrees)))
print(paste("Max k-coreness: ", max(kcore)))
return(g)
}
g <- load_network(path, filename)
dfresults <- consensus_community_detection(g,
alphas, reps, n_trials,
epsilon, res, min_p, min_vds, min_w,
echo = FALSE)
json_data <- toJSON(dfresults)
write(json_data, file=paste0(filename,"_results.json"))
print("Completed.")
dfresults  %>% filter(method == "LV") %>%
ggplot( aes(x = modularit, y =  nc , group = a)) +
facet_grid(cols = vars(a)) +
geom_line() +
geom_point() +
labs(title = "numbero of communities for alpha = (0.0 ,  0.1 , 0.2)",
x = "modularity",
y = "number of communities")
json_data <- fromJSON(paste0(filename,"_results.json"))
cols_to_extract <- c('method', "a",'rep', 'trial')
tmp_list <- list()
nn <- length(cols_to_extract)
for (i in 1:nn){
tmp_list[[i]] <- pluck(json_data, cols_to_extract[i])
}
df <- data.frame(tmp_list)
names(df) <- cols_to_extract
robs <-   pluck(json_data, "rob_mem")
n_trials = length(robs)
n_nodes <- 1000
# extract robustness, which is a list of 1000 where method == CONS
# and an empty list otherwise
for (i in 1:n_trials){
if (df$method[i] == "CONS"){
df$rob[i] <- list(robs[[i]])
} else {
df$rob[i] <- list(rep(-1, n_nodes))
}
}
# identify the node
df$id <- seq.int(nrow(df))
df <- df  %>% filter( method == "CONS")
# tidy dataset ready for plotting
df2 <- df %>%
unnest(rob) %>%
pivot_longer(cols = c(rob), names_to = 'tmp', values_to = 'rob')  %>%
select(-tmp) %>%
arrange(rep, trial, a, method, id,   rob)
df2  %>% ggplot( aes(x = rob)) +
facet_grid(cols = vars(a)) +
geom_density( adjust = 3,  color = "red") +
geom_histogram(aes(y = ..density..),
position = "identity",
alpha = 0.5) +
labs(title = "proportion of membership for alpha = (0.0 ,  0.1 , 0.2)",
x = "proportion of membership",
y = "Percentage")
filename <- "updatedgraph_1215"
library(igraph)
source('source_functions_cons_com_det.r')
path <- "./networks/"
echo = FALSE # FALSE to avoid printing intermediate results
# parameters for consensus community detection
n_trials = 10
alphas = c(0.0, 0.05, 0.1)
res = c(0.9, 1.0, 1.1)
epsilon = 1/100
# pruning
min_p <- 0.50
min_vds <- 5
min_w <- 0.01
# consensus
reps = 10
load_network <- function(path, filename) {
fn <- paste0(path,filename, ".graphml")
print(paste("Loading", fn, "..."))
g <- read_graph(fn, format = "graphml")
E(g)$ww <- E(g)$weight
V(g)$str <- strength(g)
V(g)$name <- paste0("V" , V(g)$name)
degrees <- degree(g)
kcore <- coreness(g)
print(paste("Number of nodes:", length(V(g)$name)))
print(paste("Number of edges:", length(E(g)$weight)))
print(paste("Mean degree:", mean(degrees)))
print(paste("Max k-coreness: ", max(kcore)))
return(g)
}
g <- load_network(path, filename)
dfresults <- consensus_community_detection(g,
alphas, reps, n_trials,
epsilon, res, min_p, min_vds, min_w,
echo = FALSE)
json_data <- toJSON(dfresults)
write(json_data, file=paste0(filename,"_results.json"))
print("Completed.")
dfresults  %>% filter(method == "LV") %>%
ggplot( aes(x = modularit, y =  nc , group = a)) +
facet_grid(cols = vars(a)) +
geom_line() +
geom_point() +
labs(title = "numbero of communities for alpha = (0.0 ,  0.1 , 0.2)",
x = "modularity",
y = "number of communities")
json_data <- fromJSON(paste0(filename,"_results.json"))
cols_to_extract <- c('method', "a",'rep', 'trial')
tmp_list <- list()
nn <- length(cols_to_extract)
for (i in 1:nn){
tmp_list[[i]] <- pluck(json_data, cols_to_extract[i])
}
df <- data.frame(tmp_list)
names(df) <- cols_to_extract
robs <-   pluck(json_data, "rob_mem")
n_trials = length(robs)
n_nodes <- 1000
# extract robustness, which is a list of 1000 where method == CONS
# and an empty list otherwise
for (i in 1:n_trials){
if (df$method[i] == "CONS"){
df$rob[i] <- list(robs[[i]])
} else {
df$rob[i] <- list(rep(-1, n_nodes))
}
}
# identify the node
df$id <- seq.int(nrow(df))
df <- df  %>% filter( method == "CONS")
# tidy dataset ready for plotting
df2 <- df %>%
unnest(rob) %>%
pivot_longer(cols = c(rob), names_to = 'tmp', values_to = 'rob')  %>%
select(-tmp) %>%
arrange(rep, trial, a, method, id,   rob)
df2  %>% ggplot( aes(x = rob)) +
facet_grid(cols = vars(a)) +
geom_density( adjust = 3,  color = "red") +
geom_histogram(aes(y = ..density..),
position = "identity",
alpha = 0.5) +
labs(title = "proportion of membership for alpha = (0.0 ,  0.1 , 0.2)",
x = "proportion of membership",
y = "Percentage")
filename <- "updatedgraph_1619"
library(igraph)
source('source_functions_cons_com_det.r')
path <- "./networks/"
echo = FALSE # FALSE to avoid printing intermediate results
# parameters for consensus community detection
n_trials = 10
alphas = c(0.0, 0.05, 0.1)
res = c(0.9, 1.0, 1.1)
epsilon = 1/100
# pruning
min_p <- 0.50
min_vds <- 5
min_w <- 0.01
# consensus
reps = 10
load_network <- function(path, filename) {
fn <- paste0(path,filename, ".graphml")
print(paste("Loading", fn, "..."))
g <- read_graph(fn, format = "graphml")
E(g)$ww <- E(g)$weight
V(g)$str <- strength(g)
V(g)$name <- paste0("V" , V(g)$name)
degrees <- degree(g)
kcore <- coreness(g)
print(paste("Number of nodes:", length(V(g)$name)))
print(paste("Number of edges:", length(E(g)$weight)))
print(paste("Mean degree:", mean(degrees)))
print(paste("Max k-coreness: ", max(kcore)))
return(g)
}
g <- load_network(path, filename)
dfresults <- consensus_community_detection(g,
alphas, reps, n_trials,
epsilon, res, min_p, min_vds, min_w,
echo = FALSE)
json_data <- toJSON(dfresults)
write(json_data, file=paste0(filename,"_results.json"))
print("Completed.")
dfresults  %>% filter(method == "LV") %>%
ggplot( aes(x = modularit, y =  nc , group = a)) +
facet_grid(cols = vars(a)) +
geom_line() +
geom_point() +
labs(title = "numbero of communities for alpha = (0.0 ,  0.1 , 0.2)",
x = "modularity",
y = "number of communities")
json_data <- fromJSON(paste0(filename,"_results.json"))
cols_to_extract <- c('method', "a",'rep', 'trial')
tmp_list <- list()
nn <- length(cols_to_extract)
for (i in 1:nn){
tmp_list[[i]] <- pluck(json_data, cols_to_extract[i])
}
df <- data.frame(tmp_list)
names(df) <- cols_to_extract
robs <-   pluck(json_data, "rob_mem")
n_trials = length(robs)
n_nodes <- 1000
# extract robustness, which is a list of 1000 where method == CONS
# and an empty list otherwise
for (i in 1:n_trials){
if (df$method[i] == "CONS"){
df$rob[i] <- list(robs[[i]])
} else {
df$rob[i] <- list(rep(-1, n_nodes))
}
}
# identify the node
df$id <- seq.int(nrow(df))
df <- df  %>% filter( method == "CONS")
# tidy dataset ready for plotting
df2 <- df %>%
unnest(rob) %>%
pivot_longer(cols = c(rob), names_to = 'tmp', values_to = 'rob')  %>%
select(-tmp) %>%
arrange(rep, trial, a, method, id,   rob)
df2  %>% ggplot( aes(x = rob)) +
facet_grid(cols = vars(a)) +
geom_density( adjust = 3,  color = "red") +
geom_histogram(aes(y = ..density..),
position = "identity",
alpha = 0.5) +
labs(title = "proportion of membership for alpha = (0.0 ,  0.1 , 0.2)",
x = "proportion of membership",
y = "Percentage")
